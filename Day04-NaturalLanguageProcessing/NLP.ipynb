{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83AuGdkQsp3Z"
      },
      "source": [
        "In questo notebook faremo degli esperimenti di NLP\n",
        "Iniziamo con un po' \"import\" di librerie già pronte che ci serviranno.\n",
        "Per i più \"smanettoni\", useremo la libreria NLTK che ci offre degli strumenti già pronti per fare pratica con NLP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDF0nadZriYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98112610-3a4b-461f-b186-df66aa59df82"
      },
      "source": [
        "!pip install wikipedia\n",
        "!wget https://github.com/romario076/NLP-with-Simpsons/raw/master/simpsons_dataset.csv\n",
        "!wget https://raw.githubusercontent.com/marcozullich/IntroToAi21/master/Day04-NaturalLanguageProcessing/nlp_aux.py\n",
        "from nlp_aux import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.5.30)\n",
            "--2021-09-02 13:50:05--  https://github.com/romario076/NLP-with-Simpsons/raw/master/simpsons_dataset.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/romario076/NLP-with-Simpsons/master/simpsons_dataset.csv [following]\n",
            "--2021-09-02 13:50:06--  https://raw.githubusercontent.com/romario076/NLP-with-Simpsons/master/simpsons_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9214881 (8.8M) [text/plain]\n",
            "Saving to: ‘simpsons_dataset.csv.1’\n",
            "\n",
            "simpsons_dataset.cs 100%[===================>]   8.79M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-02 13:50:06 (84.4 MB/s) - ‘simpsons_dataset.csv.1’ saved [9214881/9214881]\n",
            "\n",
            "--2021-09-02 13:50:06--  https://raw.githubusercontent.com/marcozullich/IntroToAi21/master/Day04-NaturalLanguageProcessing/nlp_aux.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3610 (3.5K) [text/plain]\n",
            "Saving to: ‘nlp_aux.py.1’\n",
            "\n",
            "nlp_aux.py.1        100%[===================>]   3.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-02 13:50:06 (40.1 MB/s) - ‘nlp_aux.py.1’ saved [3610/3610]\n",
            "\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Package omw is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBsPYav6iu2k"
      },
      "source": [
        "Proviamo a costruire un vettore \"bag of words\" dalle pagine di wikipedia di \"Gatto\", \"Matto\" e \"Felino\". Ci aspettiamo che concetti simili abbiano profili simili. (Le pagine di wiki per Gatto, Matto e Felino sono \"Felis silvestris catus\", \"Il Matto\" e \"Felidae\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5JkNPaCs-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71fdf46-5264-4545-a9f0-ba26a5b0ffa8"
      },
      "source": [
        "print(\"Profilo \"\"Gatto\"\"\")\n",
        "bow_gatto = wiki_bag_of_words(\"Felis silvestris catus\", n=10, print_bow=True)\n",
        "print(\"Profilo \"\"Matto\"\"\")\n",
        "bow_matto = wiki_bag_of_words(\"Il Matto\", n=10, print_bow=True)\n",
        "print(\"Profilo \"\"Felino\"\"\")\n",
        "bow_felino = wiki_bag_of_words(\"Felidae\", n=10, print_bow=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profilo Gatto\n",
            "di:     367\n",
            "e:     255\n",
            "il:     235\n",
            "la:     190\n",
            "gatto:     169\n",
            "è:     136\n",
            "in:     128\n",
            "che:     122\n",
            "i:     122\n",
            "del:     121\n",
            "Profilo Matto\n",
            "il:      54\n",
            "di:      46\n",
            "e:      41\n",
            "è:      37\n",
            "un:      32\n",
            "in:      32\n",
            "la:      32\n",
            "a:      20\n",
            "==:      20\n",
            "che:      20\n",
            "Profilo Felino\n",
            "-:      38\n",
            "di:      26\n",
            "gatto:      24\n",
            "e:      20\n",
            "genere:      16\n",
            "felidi:      13\n",
            "il:      12\n",
            "==:      12\n",
            "i:      11\n",
            "a:      11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVs6BT1Zjee4"
      },
      "source": [
        "Ad occhio possiamo vedere che non funziona: i profili sono molto simili e pieni di \"parole funzionali\" (stopword).\n",
        "Proviamo a misurare la distanza euclidea tra i vari profili"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYw-YtO9GaKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e1fb1e-8fa3-4f26-b915-82037278a9c0"
      },
      "source": [
        "d1 = bow_distance(bow_gatto, bow_felino)\n",
        "d2 = bow_distance(bow_gatto, bow_matto)\n",
        "print(\"Distanza tra \"\"Gatto\"\" e \"\"Felino\"\": {:.2f}\".format(d1))\n",
        "print(\"Distanza tra \"\"Gatto\"\" e \"\"Matto\"\": {:.2f}\".format(d2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distanza tra Gatto e Felino: 679.66\n",
            "Distanza tra Gatto e Matto: 622.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB6OXlprktXK"
      },
      "source": [
        "Proviamo a rimuovere le parole funzionali (stopword) e poi misuriamo le distanze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA4U0LCTD6f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d4b5f7-830f-4169-9857-4c9c9049dbcd"
      },
      "source": [
        "print(\"Profilo \"\"Gatto\"\" senza stopword\")\n",
        "bow_gatto = wiki_bag_of_words(\"Felis silvestris catus\", n=10, print_bow=True, remove_stop_words=True)\n",
        "print(\"Profilo \"\"Matto\"\" senza stopword\")\n",
        "bow_matto = wiki_bag_of_words(\"Il Matto\", n=10, print_bow=True, remove_stop_words=True)\n",
        "print(\"Profilo \"\"Felino\"\" senza stopword\")\n",
        "bow_felino = wiki_bag_of_words(\"Felidae\", n=10, print_bow=True, remove_stop_words=True)\n",
        "\n",
        "d1 = bow_distance(bow_gatto, bow_felino)\n",
        "d2 = bow_distance(bow_gatto, bow_matto)\n",
        "print(\"Distanza tra \"\"Gatto\"\" e \"\"Felino\"\": {:.2f}\".format(d1))\n",
        "print(\"Distanza tra \"\"Gatto\"\" e \"\"Matto\"\": {:.2f}\".format(d2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profilo Gatto senza stopword\n",
            "gatto:     169\n",
            "gatti:      77\n",
            "===:      54\n",
            "==:      32\n",
            "può:      31\n",
            "molto:      29\n",
            "pelo:      25\n",
            "serie:      25\n",
            "====:      22\n",
            "due:      21\n",
            "Profilo Matto senza stopword\n",
            "==:      20\n",
            "matto:      16\n",
            "the:      12\n",
            "può:      12\n",
            "altri:       9\n",
            "tarocchi:       8\n",
            "mazzi:       8\n",
            "rappresenta:       7\n",
            "spesso:       7\n",
            "tarocchi,:       7\n",
            "Profilo Felino senza stopword\n",
            "-:      38\n",
            "gatto:      24\n",
            "genere:      16\n",
            "felidi:      13\n",
            "==:      12\n",
            "famiglia:       9\n",
            "leopardus:       9\n",
            "felis:       8\n",
            "anni:       7\n",
            "lince:       7\n",
            "Distanza tra Gatto e Felino: 228.38\n",
            "Distanza tra Gatto e Matto: 237.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXgim3bSlUNo"
      },
      "source": [
        "Usiamo l'algoritmo di Cavnar-Trenkle per identificare una lingua.\n",
        "L'algoritmo costruisce un profilo linguistico per ogni lingua usando (tanti) documenti già etichettati con la loro lingua.\n",
        "Il profilo è fatto contando i 300 n-grammi più frequqnti, con ne che va da 1 a 5.\n",
        "Per identificare la lingua di un documento ignoto si construisce il profilo linguistico di questo documento e si misura la distanza di \"ranking\" tra questo e i profili delle varie lingue. Il profilo a distanza minore sarà quello delle lingua più probabile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otQHBJTDKxs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17df04fa-6041-4d62-f6e0-259b06531f74"
      },
      "source": [
        "detect_language(\"La penna è sul tavolo\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'italian'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK3fS_s1Wi7L"
      },
      "source": [
        "Inizializziamo i nostri Word2Vec. Omettiamo i dettagli, ma di fatto viene addestrata una rete neurale partendo da un corpus di dati. In questo caso i corpus sono due, il The Penn Treebank Corpus e il Movie Review Data. Il primo è una collezione di articoli dal Wall Street Journal, mentre il secondo è una collezione di critiche cinematografiche."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUpTcN686ofR"
      },
      "source": [
        "mr, t = prepare_w2v()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwXkCUH3YKFX"
      },
      "source": [
        "Usiamo la reppresentazione relativi alle review cinematografiche. Vediamo quale sono le parole più simili a `king`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoXLparbqUne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963ee2ec-6c5b-4c92-d746-817a4d81fd02"
      },
      "source": [
        "mr.wv.most_similar([\"king\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('william', 0.8669142723083496),\n",
              " ('captain', 0.8613843321800232),\n",
              " ('russell', 0.8501266241073608),\n",
              " ('chris', 0.8501229286193848),\n",
              " ('princess', 0.8481701612472534),\n",
              " ('paul', 0.8473982810974121),\n",
              " ('edward', 0.8457415103912354),\n",
              " ('jerry', 0.8456599712371826),\n",
              " ('steve', 0.8435994386672974),\n",
              " ('ryan', 0.8433903455734253)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFgcraLbYuLV"
      },
      "source": [
        "Proviamo qualcosa di più interessante. Prendiamo la parola `edward`, togliamoci `man` e aggiungiamo `woman`. la formula sarebbe `edward - man + woman`, raggruppiamo i termini positivi (`edward` e `woman`) e quelli negativi (`man`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcMBkbCM6o3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b350e2-1f19-4f9b-f3f7-85d208783edc"
      },
      "source": [
        "mr.wv.most_similar(positive=[\"edward\",\"woman\"],negative=[\"man\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('jennifer', 0.9326844215393066),\n",
              " ('jason', 0.9323540329933167),\n",
              " ('matthew', 0.9318374395370483),\n",
              " ('catherine', 0.9301232695579529),\n",
              " ('natasha', 0.9300231337547302),\n",
              " ('gwyneth', 0.9294590950012207),\n",
              " ('paltrow', 0.9248737096786499),\n",
              " ('natalie', 0.9241241812705994),\n",
              " ('brad', 0.9228675365447998),\n",
              " ('taylor', 0.9212929010391235)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkw4a0ozZKe8"
      },
      "source": [
        "Vediamo, dato un insieme di parole, quale non c'entra con le altre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09Fq7XpG796W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "f3854349-7b4f-432c-bc84-73161032ef66"
      },
      "source": [
        "mr.wv.doesnt_match([\"king\",\"queen\",\"car\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'car'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6FOvbALZQLL"
      },
      "source": [
        "Proviamo con un corpus diverso. Useremo i dialoghi delle puntate de I Simpson. Il modello va addestrato, ci vuole un po'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWgRfs6zCncO"
      },
      "source": [
        "simp = prepare_simpson()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i17p5oiZbJz"
      },
      "source": [
        "Cerchiamo la parola più simile a `simpson`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJ4MWIUEd9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d959a022-69e1-4d9c-a2dc-ae215d948db1"
      },
      "source": [
        "simp.wv.most_similar(positive=[\"simpson\"], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('homer', 0.5793749690055847)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cHJ7m2AZfm7"
      },
      "source": [
        "Prendiamo `homer`, togliomo `man` e aggiungiamo `woman`: la formula sarebbe `homer - man + woman`, raggruppiamo i termini positivi (`homer` e `woman`) e quelli negativi (`man`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZFkLA4_FY43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1799068d-4971-4eae-92e1-9c2d3ae3fe14"
      },
      "source": [
        "simp.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"man\"], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('marge', 0.3963927626609802)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOuIaqy1VV_C"
      },
      "source": [
        "Stessa cosa, ma con `bart` (e `boy` e `girl`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixSkD-q2ElLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3942878-e750-40e0-ea5a-fa9d10d8a31c"
      },
      "source": [
        "simp.wv.most_similar(positive=[\"bart\", \"girl\"], negative=[\"boy\"], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lisa', 0.41597259044647217)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZf9oZ4bZpWK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}